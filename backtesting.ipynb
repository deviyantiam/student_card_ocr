{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library Required for this notebook\n",
    "from student_id_ocr.ocr_student_card import StudentCardReader\n",
    "\n",
    "# Utility Module\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = r'C:\\Users\\deviy\\Desktop\\ocr_student_service\\asset'\n",
    "df=pd.read_csv('test_actual.csv',quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>name</th>\n",
       "      <th>member_id</th>\n",
       "      <th>phone</th>\n",
       "      <th>address</th>\n",
       "      <th>district</th>\n",
       "      <th>district_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.png</td>\n",
       "      <td>Lily Johnson</td>\n",
       "      <td>123-789-4560</td>\n",
       "      <td>+123-999-7890</td>\n",
       "      <td>123 Imaginary Avenue, Dreamland, DL 00000</td>\n",
       "      <td>Dreamland</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.png</td>\n",
       "      <td>Michael Taylor</td>\n",
       "      <td>123-876-5430</td>\n",
       "      <td>+123-333-4444</td>\n",
       "      <td>808 Willow Way, Riverside, RS 77777</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>RS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.png</td>\n",
       "      <td>Benjamin William</td>\n",
       "      <td>123-234-5681</td>\n",
       "      <td>+123-111-3322</td>\n",
       "      <td>101 Cedar Lane, Hilltop, HT 44444</td>\n",
       "      <td>Hilltop</td>\n",
       "      <td>HT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.png</td>\n",
       "      <td>Jacob Miller</td>\n",
       "      <td>123-024-8190</td>\n",
       "      <td>+123-001-1224</td>\n",
       "      <td>321 Oak Street, Riverdale, RD 11111</td>\n",
       "      <td>Riverdale</td>\n",
       "      <td>RD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.png</td>\n",
       "      <td>Mia Wilson</td>\n",
       "      <td>123-876-5430</td>\n",
       "      <td>+123-333-4444</td>\n",
       "      <td>808 Rainbow Lane, Unicorn Valley, UV, 66666</td>\n",
       "      <td>Unicorn Valley</td>\n",
       "      <td>UV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.png</td>\n",
       "      <td>Matthew Garcia</td>\n",
       "      <td>123-345-6782</td>\n",
       "      <td>+123-999-0010</td>\n",
       "      <td>999 Oakwood Drive, Hillcrest, HC, 00000</td>\n",
       "      <td>Hillcrest</td>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename              name     member_id          phone  \\\n",
       "0    1.png      Lily Johnson  123-789-4560  +123-999-7890   \n",
       "1   10.png    Michael Taylor  123-876-5430  +123-333-4444   \n",
       "2   12.png  Benjamin William  123-234-5681  +123-111-3322   \n",
       "3   14.png      Jacob Miller  123-024-8190  +123-001-1224   \n",
       "4    6.png        Mia Wilson  123-876-5430  +123-333-4444   \n",
       "5    7.png    Matthew Garcia  123-345-6782  +123-999-0010   \n",
       "\n",
       "                                       address        district district_code  \n",
       "0    123 Imaginary Avenue, Dreamland, DL 00000       Dreamland            DL  \n",
       "1          808 Willow Way, Riverside, RS 77777       Riverside            RS  \n",
       "2            101 Cedar Lane, Hilltop, HT 44444         Hilltop            HT  \n",
       "3          321 Oak Street, Riverdale, RD 11111       Riverdale            RD  \n",
       "4  808 Rainbow Lane, Unicorn Valley, UV, 66666  Unicorn Valley            UV  \n",
       "5      999 Oakwood Drive, Hillcrest, HC, 00000       Hillcrest            HC  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run OCR\n",
    "def run_ocr(model_path, directory, df, output_file):\n",
    "    ocr_result = pd.DataFrame()\n",
    "    for img_path in df['filename']:\n",
    "        sc_result=StudentCardReader(model_path=model_path).run_ocr(os.path.join(directory,img_path))\n",
    "        sc_df = sc_result.to_df()\n",
    "        sc_df['filename']=img_path\n",
    "        ocr_result=ocr_result._append(sc_df)\n",
    "    ocr_result.to_csv(output_file,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "model_path = r'C:\\Users\\deviy\\Desktop\\ocr_student_service\\student_card_model'\n",
    "output_file = 'test_predict_model_v1.csv'\n",
    "run_ocr(model_path, directory, df, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "model_path = r'C:\\Users\\deviy\\Desktop\\ocr_student_service\\student_card_model_v2'\n",
    "output_file = 'test_predict_model_v2.csv'\n",
    "run_ocr(model_path, directory, df, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r'C:\\Users\\deviy\\Desktop\\ocr_student_service\\asset\\rotated'\n",
    "df=pd.read_csv('test_actual_rotated.csv',quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "model_path = r'C:\\Users\\deviy\\Desktop\\ocr_student_service\\student_card_model_v2'\n",
    "output_file = 'test_predict_model_rotated_v2.csv'\n",
    "run_ocr(model_path, directory, df, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r'C:\\Users\\deviy\\Desktop\\ocr_student_service\\asset\\test_detectron.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Student Card file: test_detectron.png\n",
       "Status: NotOK\n",
       "\n",
       "name: \n",
       "member_id: 123-456-7820\n",
       "phone_number: \n",
       "address: \n",
       "district: \n",
       "district_code: "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StudentCardReader(model_path=model_path).run_ocr(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.path.join(dir_path, filename)\n",
    "model_path = Path(r'C:\\Users\\deviy\\Desktop\\ocr_student_service\\student_card_model_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "from student_id_ocr.preprocessing import (\n",
    "    CornerDetectionGrayscaleThresholdingPreprocessing\n",
    ")\n",
    "from student_id_ocr.postprocessing import WordCoordPostprocessing\n",
    "from student_id_ocr.abstract_class import (\n",
    "    RunStudentCardOCR,\n",
    "    PreprocessingStudentCardOCR,\n",
    "    PostprocessingStudentCardOCR,\n",
    "    StudentCardBase,\n",
    ")\n",
    "from student_id_ocr.student_card import StudentCardInformation, StudentCardObject\n",
    "from student_id_ocr.corner_detection import load_model\n",
    "from student_id_ocr.config_student_card import EASY_OCR_CONFIG\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import base64\n",
    "import cv2\n",
    "\n",
    "model_path = r'C:\\Users\\deviy\\Desktop\\ocr_student_service\\student_card_model_v2'\n",
    "OCR = easyocr.Reader(\n",
    "    lang_list=[\"en\"],\n",
    "    gpu=False,\n",
    "    recog_network=EASY_OCR_CONFIG[\"FILE_NAME\"],\n",
    "    model_storage_directory=str(\n",
    "        os.path.join(model_path,  EASY_OCR_CONFIG[\"MODEL_PATH\"])\n",
    "    ),\n",
    "    user_network_directory=str(\n",
    "        os.path.join(model_path,EASY_OCR_CONFIG[\"USER_NETWORK_PATH\"])\n",
    "    ),\n",
    ")\n",
    "\n",
    "student_card_detection = load_model(os.path.join(model_path, EASY_OCR_CONFIG[\"PREPRO_CONFIG\"]))\n",
    "preprocessing_class = CornerDetectionGrayscaleThresholdingPreprocessing\n",
    "_prepro = preprocessing_class(student_card_detection)\n",
    "\n",
    "img = cv2.imread(str(img_path))[..., ::-1]\n",
    "\n",
    "# Run preprocessing\n",
    "input_img = _prepro.preprocessing(img)\n",
    "ocr_output = OCR.readtext(input_img, width_ths=1, contrast_ths=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([[70, 20], [306, 20], [306, 46], [70, 46]],\n",
       "  'DAWALE ACADEMY OF',\n",
       "  0.9718502849791392),\n",
       " ([[331, 37], [411, 37], [411, 51], [331, 51]],\n",
       "  'Surr DCrd',\n",
       "  0.05604309175389802),\n",
       " ([[71, 42], [162, 42], [162, 70], [71, 70]], 'MEDICINE', 0.9995111424261114),\n",
       " ([[225, 101], [261, 101], [261, 113], [225, 113]],\n",
       "  'Nimo',\n",
       "  0.36542701721191406),\n",
       " ([[227, 111], [315, 111], [315, 131], [227, 131]],\n",
       "  'Emma Smith',\n",
       "  0.9971947571398476),\n",
       " ([[225, 137], [287, 137], [287, 151], [225, 151]],\n",
       "  'Membtt ID',\n",
       "  0.2006426652113668),\n",
       " ([[225, 153], [303, 153], [303, 169], [225, 169]],\n",
       "  '123-456-7820',\n",
       "  0.5796789031972086),\n",
       " ([[225, 175], [263, 175], [263, 189], [225, 189]],\n",
       "  'Pnone',\n",
       "  0.6545018478525081),\n",
       " ([[225, 189], [309, 189], [309, 205], [225, 205]],\n",
       "  '+123-456-7890',\n",
       "  0.4600291966952959),\n",
       " ([[223, 213], [271, 213], [271, 227], [223, 227]],\n",
       "  'Addre >',\n",
       "  0.3097024101147117),\n",
       " ([[223, 227], [421, 227], [421, 243], [223, 243]],\n",
       "  '123 Anyiere SLAny Cry.ST 12345',\n",
       "  0.15447296216273274)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from student_id_ocr.abstract_class import PostprocessingStudentCardOCR\n",
    "from student_id_ocr.student_card import StudentCardInformation, StudentCardInfoBase\n",
    "from student_id_ocr.config_student_card import WORD_COORD_CONFIG\n",
    "from typing import Dict, Iterable, Union\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jellyfish\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "class WordCoordPostprocessing(PostprocessingStudentCardOCR):\n",
    "    \"\"\"Postprocessing method for pd.DataFrame word coordinate from OCR Output\"\"\"\n",
    "\n",
    "    def __init__(self, model_dir: Union[Path, str]) -> None:\n",
    "        \"\"\"Initialization of Word Coordinate PostProcessing\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_dir : Union[Path, str]\n",
    "            Path to model directory to get config.json\n",
    "        img_shape : Any[Tuple, None], optional\n",
    "            Input Image Shape for grouping, by default None\n",
    "        \"\"\"\n",
    "        CONFIG_PATH = model_dir / WORD_COORD_CONFIG[\"WORD_COOR\"]\n",
    "        if not CONFIG_PATH.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"\"\"\n",
    "        Config File for OCR Model doesn't exists in {CONFIG_PATH}\n",
    "        \"\"\"\n",
    "            )\n",
    "        with open(CONFIG_PATH, \"r\") as file:\n",
    "            CONFIG_WORD = json.load(file)\n",
    "        self.word_coord_cols = [\"word\", \"p1\", \"p2\", \"p3\", \"p4\"]\n",
    "        self.form = StudentCardInformation()\n",
    "        self.puncts = \"!\\\"#$%&()*:;—,.'<=>?@[\\]^_`{|}~“\"\n",
    "        self._input_img_shape = None\n",
    "        self.split_y_pct = 0.45\n",
    "        try:\n",
    "            self.cols = CONFIG_WORD[\"col\"]\n",
    "            self.district_list =  [district[\"name\"] for district in CONFIG_WORD[\"district\"]]\n",
    "            self.distric_mapping = CONFIG_WORD[\"district\"]\n",
    "            self.field_words = CONFIG_WORD[\"field_words\"]\n",
    "        except Exception as e:\n",
    "            raise FileNotFoundError(\n",
    "                \"error getting values of config file\"\n",
    "            )\n",
    "        \n",
    "    @property\n",
    "    def img_shape(self):\n",
    "        return self._input_img_shape\n",
    "\n",
    "    @img_shape.setter\n",
    "    def img_shape(self, shape):\n",
    "        self._input_img_shape = shape\n",
    "\n",
    "    def postprocessing(self, ocr_output: pd.DataFrame) -> StudentCardInfoBase:\n",
    "        \"\"\"Postprocessing method by grouping bounding box and word to get KTP form object\"\"\"\n",
    "        if not ocr_output.columns.isin(self.word_coord_cols).all():\n",
    "            raise ValueError(f\" ocr_output should contain columns: {self.cols}\")\n",
    "        # save ocr_output to object atributes\n",
    "        self.ocr_output = ocr_output\n",
    "        # Grouping the Words by binning the middle points to create one row\n",
    "        self.ocr_output[\"middle_x\"] = self.calculate_middle(0)\n",
    "        self.ocr_output[\"middle_y\"] = self.calculate_middle(1)\n",
    "        self.ocr_output.sort_values(by=[\"middle_y\", \"middle_x\"], inplace=True)\n",
    "        self.ocr_output[\"bin_x\"] = self.assign_bin_x()\n",
    "        \n",
    "        self.z_order()\n",
    "        corrected_cols = self.get_similar_word(self.ocr_output[\"word\"], self.field_words, 0.9)\n",
    "        if len(corrected_cols) > 0:\n",
    "            for key, value in corrected_cols.items():\n",
    "                self.ocr_output.loc[self.ocr_output['word'] == key, 'field'] = value\n",
    "\n",
    "        last_field = self.get_last_field([i for i in self.ocr_output[\"field\"] if i!='' or not pd.isna(i)])\n",
    "        self.ocr_output[\"field\"] = self.ocr_output[\"field\"].replace('', np.nan)\n",
    "        self.ocr_output['prev_value'] = self.ocr_output['field'].shift(1)\n",
    "        self.ocr_output['prev_value'] = self.ocr_output['prev_value'].ffill()\n",
    "        self.ocr_output['prev_value'] = self.ocr_output['prev_value'].str.lower().str.replace(' ', '_')\n",
    "        self.ocr_output.reset_index(drop=True, inplace=True)\n",
    "        self.extract_info(last_field)\n",
    "        self.add_district_info(var_similarity=0.9)\n",
    "        return self.form\n",
    "\n",
    "    def get_similar_word(\n",
    "        self, word_result: Iterable[str], word_sim: Iterable[str], conf: float\n",
    "    ) -> Dict:\n",
    "        \"\"\"Get similar word based on list of word dictionary\n",
    "        Using jaro winkler similarity\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        word_result : Iterable\n",
    "            Result of OCR\n",
    "        word_sim : Iterable\n",
    "            Word Dictionary\n",
    "        conf : float\n",
    "            Confidence (0 - 1)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict\n",
    "            String with Replaced dictionary, if not found will throw nan.\n",
    "        \"\"\"\n",
    "        corrected = {}\n",
    "        for word in word_result:\n",
    "            sim = [\n",
    "                (form, jellyfish.jaro_winkler_similarity(word, form))\n",
    "                for form in word_sim\n",
    "            ]\n",
    "            max_sim = max(sim, key=lambda x: x[1])\n",
    "            if max_sim[1] >= conf:\n",
    "                corrected[word] = max_sim[0]\n",
    "            else:\n",
    "                corrected[word] = np.nan\n",
    "\n",
    "        return corrected\n",
    "\n",
    "    def calculate_middle(self, axis: int) -> list:\n",
    "        middles = []\n",
    "        for _, rows in self.ocr_output.iterrows():\n",
    "            middle = (\n",
    "                int(rows.p1[axis])\n",
    "                + int(rows.p2[axis])\n",
    "                + int(rows.p3[axis])\n",
    "                + int(rows.p4[axis])\n",
    "            ) / 4\n",
    "            middles.append(middle)\n",
    "        return middles\n",
    "\n",
    "    def z_order(self):\n",
    "        if \"bin_x\" not in self.ocr_output:\n",
    "            raise NotImplementedError(\n",
    "                \"bin_x not found in ocr_output, please run x axis grouping first\"\n",
    "            )\n",
    "        iter_df = []\n",
    "        for group in self.ocr_output[\"bin_x\"].unique():\n",
    "            group_df = (\n",
    "                self.ocr_output.query(f\"bin_x=={group}\")\n",
    "                .sort_values(\"middle_y\")\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            idx_done = []\n",
    "            for idx, row in group_df.iterrows():\n",
    "                if idx in idx_done:\n",
    "                    continue\n",
    "                if row[\"p1\"][1] != row[\"p2\"][1]:\n",
    "                    top_y, bottom_y = row[\"p1\"][1], row[\"p2\"][1]\n",
    "                else:\n",
    "                    bottom_y = max(\n",
    "                        [row[\"p1\"][1], row[\"p2\"][1], row[\"p3\"][1], row[\"p4\"][1]]\n",
    "                    )\n",
    "                    top_y = min(\n",
    "                        [row[\"p1\"][1], row[\"p2\"][1], row[\"p3\"][1], row[\"p4\"][1]]\n",
    "                    )\n",
    "                row_df = group_df.loc[\n",
    "                    (group_df[\"middle_y\"] >= top_y) & (group_df[\"middle_y\"] <= bottom_y)\n",
    "                ].sort_values(\"middle_x\")\n",
    "                row_df = row_df[~row_df.index.isin(idx_done)]\n",
    "                idx_done += row_df.index.to_list()\n",
    "                row_df[\"bin_y\"] = idx\n",
    "                iter_df.append(row_df)\n",
    "\n",
    "        self.ocr_output = pd.concat(iter_df, axis=0)\n",
    "\n",
    "    def assign_bin_x(self) -> np.array:\n",
    "        \"\"\"Group KTP Text whether it's in the left side such as nama, alamat\n",
    "        or in the right side like gol darah or date issued\"\"\"\n",
    "        bin_x = np.where(\n",
    "            self.ocr_output[\"p1\"].str[0] > self.img_shape[1] * self.split_y_pct,\n",
    "            1,  # if correct (right)\n",
    "            0,  # else (left)\n",
    "        )\n",
    "        # Force first few lines to be left side\n",
    "        bin_x[:4] = 0\n",
    "        return bin_x\n",
    "    \n",
    "    def get_last_field(self, cleaned_df_list):\n",
    "        for field in reversed(self.field_words):\n",
    "            if field in cleaned_df_list:\n",
    "                return field\n",
    "        return None\n",
    "    \n",
    "    def extract_info(self, last_label):\n",
    "        for index, row in self.ocr_output.iterrows():\n",
    "            if row['field'] == 'Name' and self.form.name=='':\n",
    "                self.form.name = ' '.join([row['word'] for i, row in self.ocr_output.iloc[index:index+4].iterrows() if pd.isna(row['field']) and row['prev_value'] == 'name'])\n",
    "            elif row['field'] == 'Member ID' and self.form.member_id=='':\n",
    "                self.form.member_id = ' '.join([row['word'] for i, row in self.ocr_output.iloc[index:index+2].iterrows() if pd.isna(row['field']) and row['prev_value'] == 'member_id'])\n",
    "            elif row['field'] == 'Phone' and  self.form.phone_number=='':\n",
    "                self.form.phone_number = ' '.join([row['word'] for i, row in self.ocr_output.iloc[index:index+2].iterrows() if pd.isna(row['field']) and row['prev_value'] == 'phone'])\n",
    "            elif row['field'] == 'Address' and self.form.address=='':\n",
    "                self.form.address = ' '.join([row['word'] for i, row in self.ocr_output.iloc[index:index+5].iterrows() if pd.isna(row['field']) and row['prev_value'] == 'address'])\n",
    "            if row['field'] == last_label:\n",
    "                break  # Stop iteration once last_label is found\n",
    "         \n",
    "    \n",
    "    def get_district_code(self, district_name):\n",
    "        for district in self.distric_mapping:\n",
    "            if district[\"name\"] == district_name:\n",
    "                return district['code']\n",
    "        return ''\n",
    "\n",
    "    def add_district_info(self, var_similarity):\n",
    "        corrected_district = np.nan\n",
    "        temp_address = ''\n",
    "        if self.form.address or self.form.address!='' :\n",
    "            address_parts = self.form.address.split(', ')\n",
    "            if len(address_parts)>1:\n",
    "                last_address_part = address_parts[-1]\n",
    "                if any(char.isdigit() for char in last_address_part): \n",
    "                    if len(address_parts[-2]) > 2:\n",
    "                        corrected_district = self.get_similar_word(\n",
    "                                    [address_parts[-2]], self.district_list, var_similarity\n",
    "                                )[address_parts[-2]]\n",
    "                        temp_address = address_parts[-2]\n",
    "                    else:\n",
    "                        corrected_district = self.get_similar_word(\n",
    "                                    [address_parts[-3]], self.district_list, var_similarity\n",
    "                                )[address_parts[-3]]\n",
    "                        temp_address = address_parts[-3]\n",
    "                self.form.district = (\n",
    "                                corrected_district\n",
    "                                if corrected_district is not np.nan\n",
    "                                else temp_address\n",
    "                            )\n",
    "                self.form.district_code =  self.get_district_code(self.form.district)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ocr_output = [([[137, 39], [618, 39], [618, 90], [137, 90]],\n",
    "  'DAWNALE ACADEM OF',\n",
    "  0.7931522201397618),\n",
    " ([[674, 69], [842, 69], [842, 99], [674, 99]],\n",
    "  'Student ID Card',\n",
    "  0.9997962604958386),\n",
    " ([[137, 88], [318, 88], [318, 136], [137, 136]],\n",
    "  'MEDICINE',\n",
    "  0.999964301355374),\n",
    " ([[454, 204], [524, 204], [524, 228], [454, 228]],\n",
    "  'Name',\n",
    "  0.9988865586884293),\n",
    " ([[453, 229], [641, 229], [641, 265], [453, 265]],\n",
    "  'Emma Smith',\n",
    "  0.9891406234196626),\n",
    " ([[454, 280], [578, 280], [578, 306], [454, 306]],\n",
    "  'Member ID',\n",
    "  0.9996052641237478),\n",
    " ([[452, 312], [612, 312], [612, 338], [452, 338]],\n",
    "  '123-456-7890',\n",
    "  0.9519679660149585),\n",
    " ([[451, 355], [526, 355], [526, 382], [451, 382]],\n",
    "  'Phone',\n",
    "  0.9999739303845567),\n",
    " ([[450, 386], [624, 386], [624, 414], [450, 414]],\n",
    "  '+123-456-7890',\n",
    "  0.7066969207315418),\n",
    " ([[452, 432], [548, 432], [548, 458], [452, 458]],\n",
    "  'Address',\n",
    "  0.9999934216890737),\n",
    " ([[450, 464], [858, 464], [858, 496], [450, 496]],\n",
    "  '123 Anywhere St, Any City, ST 12345',\n",
    "  0.7199318014784352)]\n",
    "    \n",
    "    def _get_word_coord(ocr_output: list) -> pd.DataFrame:\n",
    "        \"\"\"Extract Word and Coordinate from OCR Output\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ocr_output : list\n",
    "            output from EasyOCR\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Dataframe of Word and Coordinate\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        for line in ocr_output:\n",
    "            p1, p3, p4, p2 = line[0]\n",
    "            data.append([line[1], p1, p2, p3, p4])\n",
    "        word_coord = pd.DataFrame(data, columns=[\"word\", \"p1\", \"p2\", \"p3\", \"p4\"])\n",
    "        return word_coord\n",
    "    \n",
    "    model_path = r'C:\\Users\\deviy\\Desktop\\ocr_train\\student_card_model'\n",
    "    model_path = Path(model_path)\n",
    "    postprocessing_class= WordCoordPostprocessing\n",
    "    postpro = postprocessing_class(model_path)\n",
    "    postpro.img_shape = (562, 925)\n",
    "\n",
    "    word_coord_df = _get_word_coord(ocr_output)\n",
    "                # Run post procesing on ocr_output\n",
    "    student_form = postpro.postprocessing(word_coord_df)\n",
    "    from student_id_ocr.student_card import  StudentCardObject\n",
    "    img_path = r'C:\\Users\\deviy\\Desktop\\ocr_train\\data\\train\\0.png'\n",
    "    img_path= Path(img_path)\n",
    "    print(StudentCardObject(student_form,img_path))\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ddf5729a28c444c66b2216dc3f8b9c5dc88a76c225e98876a2d778cd6333114"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
